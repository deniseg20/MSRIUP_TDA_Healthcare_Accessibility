{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Distance Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "AUv90Ejml1SS",
    "outputId": "c5db59f5-a8f3-49ec-ea07-f4e286892bc6"
   },
   "outputs": [],
   "source": [
    "## Modules\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import urllib.request\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cars_by_county = pd.read_csv(r'county_vr_proportions.csv', index_col = 0, header=0)\n",
    "#cars_by_county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Locations (FQHCs and PPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_centers = pd.read_csv(r'facilities_w_county.csv', index_col = 0, header=0)\n",
    "health_centers.index.tolist()\n",
    "county_pop = pd.read_csv(r'county_vr_proportions.csv', index_col = 0, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAUFIeGGl4aI"
   },
   "outputs": [],
   "source": [
    "## Utils\n",
    "'''health_centers = pd.read_csv(r'facilities_w_county.csv', index_col = 0, header=0)\n",
    "health_centers.index.tolist()\n",
    "county_pop = pd.read_csv(r'county_vr_proportions.csv', index_col = 0, header = 0)'''\n",
    "\n",
    "def get_county(site, health_centers):\n",
    "    return health_centers.loc[site]['county']\n",
    "def get_pop(county_name):\n",
    "    # Remove \"County\" from the end and convert to lowercase for matching\n",
    "    county_normalized = county_name.lower().replace(\" county\", \"\").strip()\n",
    "    \n",
    "    # Find matching county in county_pop dataframe (case-insensitive)\n",
    "    county_match = county_pop[county_pop['Counties'].str.lower() == county_normalized]\n",
    "    \n",
    "    # Check if match was found\n",
    "    if county_match.empty:\n",
    "        print(f\"No match found for county: {county_name} (normalized: {county_normalized})\")\n",
    "        return 0  # Return 0 instead of None\n",
    "    \n",
    "    # Return the population value\n",
    "    return int(county_match['Total_Population'].iloc[0])\n",
    "def get_car_prop(site, health_centers):\n",
    "    county = get_county(site, health_centers)\n",
    "    # Remove \"County\" from the end and convert to lowercase for matching\n",
    "    county_normalized = county.lower().replace(\" county\", \"\").strip()\n",
    "    \n",
    "    # Find the car proportion for this county in county_pop\n",
    "    county_match = county_pop[county_pop['Counties'].str.lower() == county_normalized]\n",
    "    \n",
    "    if county_match.empty:\n",
    "        print(f\"No match found for county: {county} (normalized: {county_normalized})\")\n",
    "        return 0.0  # Return a default value instead of None\n",
    "    \n",
    "    return county_match['Vehicle_Registration_Proportion'].iloc[0]\n",
    "\n",
    "\n",
    "'''def get_county(site, health_centers): #changed from get_zip to get_county\n",
    "    #return health_centers.loc[site]['county']\n",
    "    county = get_county(site, health_centers)\n",
    "    # Find the car proportion for this county in county_pop\n",
    "    county_match = county_pop[county_pop['Counties'].str.lower() == county.lower()]\n",
    "    if county_match.empty:\n",
    "        print(f\"No match found for county: {county}\")\n",
    "        return None\n",
    "    return county_match['Vehicle_Registration_Proportion'].iloc[0]'''\n",
    "\n",
    "def calc_dtilde_matrix(health_centers, t_car, t_pub, t_walk):\n",
    "    N = health_centers.shape[0]\n",
    "    dtilde_matrix = np.zeros((N,N))\n",
    "    \n",
    "    index_to_pos = {idx: pos for pos, idx in enumerate(health_centers.index)}\n",
    "    \n",
    "    for i, a in health_centers.iterrows():\n",
    "        for j, b in health_centers.iterrows():\n",
    "            if i != j:\n",
    "                # for walking \n",
    "                pos_i = index_to_pos[i]\n",
    "                pos_j = index_to_pos[j]\n",
    "                \n",
    "                if (t_walk.iloc[pos_i,pos_j] == 0 and t_walk.iloc[pos_j,pos_i] == 0):\n",
    "                    walk = 0\n",
    "                elif t_walk.iloc[pos_i,pos_j]==0:\n",
    "                    walk=2*t_walk[pos_j,i]\n",
    "                elif t_walk.iloc[pos_j,pos_i] == 0:\n",
    "                    walk=2*t_walk.iloc[pos_i, pos_j]\n",
    "                else: \n",
    "                    walk = t_walk.iloc[pos_i,pos_j] + t_walk.iloc[pos_j,pos_i] \n",
    "                # for public transport\n",
    "                if t_pub.iloc[pos_i,pos_j] == 0 and t_pub.iloc[pos_j,pos_i] == 0:\n",
    "                    pub = 0\n",
    "                elif t_pub.iloc[pos_i,pos_j] == 0:\n",
    "                    pub = 2*t_pub.iloc[pos_j,pos_i]\n",
    "                elif t_pub.iloc[pos_j,pos_i] == 0:\n",
    "                    pub = 2*t_pub.iloc[pos_i,pos_j]\n",
    "                else:\n",
    "                    pub = t_pub.iloc[pos_i,pos_j] + t_pub.iloc[pos_j,pos_i]\n",
    "                # for car\n",
    "                if t_car.iloc[pos_i,pos_j] == 0 and t_car.iloc[pos_j,pos_i] == 0:\n",
    "                    car = 0\n",
    "                elif t_car.iloc[pos_i,pos_j] == 0:\n",
    "                    car = 2*t_car.iloc[pos_j,pos_i]\n",
    "                elif t_car.iloc[pos_j,pos_i] == 0:\n",
    "                    car=2*t_car.iloc[pos_i,pos_j]\n",
    "                else:\n",
    "                    car = t_car.iloc[pos_i,pos_j] + t_car.iloc[pos_j,pos_i]\n",
    "                    \n",
    "                driver_min = min(walk, pub, car)\n",
    "                non_driver_min = min(walk, pub)\n",
    "                car_prop = get_car_prop(i, health_centers)\n",
    "                \n",
    "                dtilde_matrix[pos_i,pos_j] = car_prop*driver_min + (1-car_prop)*non_driver_min\n",
    "    return dtilde_matrix\n",
    "\n",
    "def calc_d_matrix(dtilde_matrix, health_centers):\n",
    "    N = health_centers.shape[0]\n",
    "    d_matrix = np.zeros((N,N))\n",
    "    index_to_pos = {idx: pos for pos, idx in enumerate(health_centers.index)}\n",
    "    \n",
    "    for i, a in health_centers.iterrows():\n",
    "        for j, b in health_centers.iterrows():\n",
    "            if i != j:\n",
    "                pos_i = index_to_pos[i]\n",
    "                pos_j = index_to_pos[j]\n",
    "                county_i = get_county(i, health_centers)\n",
    "                county_j = get_county(j, health_centers)\n",
    "                \n",
    "                #popi = get_pop(county_i)\n",
    "                #popj = get_pop(county_j)\n",
    "                popi = get_pop(county_i) # ERROR\n",
    "                popj = get_pop(county_j)\n",
    "                if popi == 0 and popj == 0:\n",
    "                    d_matrix[pos_i,pos_j] = 0\n",
    "                elif popi == 0:\n",
    "                    d_matrix[pos_i,pos_j] = dtilde_matrix[pos_j,pos_i]\n",
    "                elif popj == 0:\n",
    "                    d_matrix[pos_i,pos_j] = dtilde_matrix[pos_i,pos_j]\n",
    "                else:\n",
    "                    d_matrix[pos_i,pos_j] = (1/(popi+popj))*(popi*dtilde_matrix[pos_i,pos_j] + popj*dtilde_matrix[pos_j,pos_i])\n",
    "\n",
    "    return d_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ux-dp2DRmN_2"
   },
   "outputs": [],
   "source": [
    "health_centers = pd.read_csv('facilities_w_county.csv',\n",
    "                        index_col=0,\n",
    "                        header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrix for all 411 locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NL9gxx61mt-w"
   },
   "outputs": [],
   "source": [
    "t_car = pd.read_csv(\"drive_matrix_all.csv\",\n",
    "                        index_col=0,\n",
    "                        header=0)\n",
    "t_pub = pd.read_csv(\"transit_matrix_all.csv\",\n",
    "                        index_col=0,\n",
    "                        header=0)\n",
    "# slc_twalk = calc_twalk_matrix(slc_sites, slc_neighbours)\n",
    "t_walk = pd.read_csv(\"walking_matrix_all.csv\",\n",
    "                        index_col=0,\n",
    "                        header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "8l-H5ZNPm5bv"
   },
   "outputs": [],
   "source": [
    "all_loc_dtilde = calc_dtilde_matrix(health_centers, t_car, t_pub, t_walk)\n",
    "all_loc_d_matrix = calc_d_matrix(all_loc_dtilde, health_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading matrix and saving to CSV for All Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"all_loc_d_matrix_updated.npy\", all_loc_d_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1           2    3           4           5    6    7    8    9    ...  \\\n",
      "0  0.0  NaN         NaN  NaN         NaN         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "1  NaN  0.0         NaN  NaN         NaN         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "2  NaN  NaN    0.000000  NaN  903.671334         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "3  NaN  NaN         NaN  0.0         NaN         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "4  NaN  NaN  903.671334  NaN    0.000000  245.742626  NaN  NaN  NaN  NaN  ...   \n",
      "\n",
      "   401         402        403  404  405  406  407  408  409         410  \n",
      "0  NaN         NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  696.437903  \n",
      "1  NaN         NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "2  NaN  232.914218        NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "3  NaN         NaN  88.047353  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "4  NaN  150.470140        NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "\n",
      "[5 rows x 411 columns]\n",
      "   0    1           2    3           4           5    6    7    8    9    ...  \\\n",
      "0  0.0  0.0    0.000000  0.0    0.000000    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "1  0.0  0.0    0.000000  0.0    0.000000    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "2  0.0  0.0    0.000000  0.0  903.671334    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "3  0.0  0.0    0.000000  0.0    0.000000    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "4  0.0  0.0  903.671334  0.0    0.000000  245.742626  0.0  0.0  0.0  0.0  ...   \n",
      "\n",
      "   401         402        403  404  405  406  407  408  409         410  \n",
      "0  0.0    0.000000   0.000000  0.0  0.0  0.0  0.0  0.0  0.0  696.437903  \n",
      "1  0.0    0.000000   0.000000  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "2  0.0  232.914218   0.000000  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "3  0.0    0.000000  88.047353  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "4  0.0  150.470140   0.000000  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "\n",
      "[5 rows x 411 columns]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"all_loc_d_matrix.npy\")\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "df = df.fillna(0)\n",
    "print(df.head())\n",
    "df.to_csv('dtilde_matrix_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrix for FQHCs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_centers = pd.read_csv(r'facilities_w_county.csv', index_col = 0, header=0)\n",
    "health_centers.index.tolist()\n",
    "county_pop = pd.read_csv(r'county_vr_proportions.csv', index_col = 0, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       FQHC1  FQHC2      FQHC3  FQHC4      FQHC5      FQHC6  FQHC7  FQHC8  \\\n",
      "FQHC1    0.0    0.0   0.000000    0.0   0.000000   0.000000    0.0    0.0   \n",
      "FQHC2    0.0    0.0   0.000000    0.0   0.000000   0.000000    0.0    0.0   \n",
      "FQHC3    0.0    0.0   0.000000    0.0  72.633333  75.533333    0.0    0.0   \n",
      "FQHC4    0.0    0.0   0.000000    0.0   0.000000   0.000000    0.0    0.0   \n",
      "FQHC5    0.0    0.0  73.583333    0.0   0.000000  62.116667    0.0    0.0   \n",
      "\n",
      "       FQHC9  FQHC10  ...  FQHC293  FQHC294    FQHC295    FQHC296  FQHC297  \\\n",
      "FQHC1    0.0     0.0  ...      0.0      0.0  52.766667   0.000000      0.0   \n",
      "FQHC2    0.0     0.0  ...      0.0      0.0   0.000000   0.000000      0.0   \n",
      "FQHC3    0.0     0.0  ...      0.0      0.0   0.000000  84.533333      0.0   \n",
      "FQHC4    0.0     0.0  ...      0.0      0.0   0.000000   0.000000      0.0   \n",
      "FQHC5    0.0     0.0  ...      0.0      0.0   0.000000  31.183333      0.0   \n",
      "\n",
      "       FQHC298    FQHC299  FQHC300  FQHC301  Unnamed: 302  \n",
      "FQHC1      0.0   0.000000      0.0      0.0           0.0  \n",
      "FQHC2      0.0   0.000000      0.0      0.0           0.0  \n",
      "FQHC3      0.0   0.000000      0.0      0.0           0.0  \n",
      "FQHC4      0.0  37.566667      0.0      0.0           0.0  \n",
      "FQHC5      0.0   0.000000      0.0      0.0           0.0  \n",
      "\n",
      "[5 rows x 302 columns]\n"
     ]
    }
   ],
   "source": [
    "# changing xlsx to csv \n",
    "#df = pd.read_excel(\"drive_minutes_matrix_fqhc.xlsx\", index_col=0, header=0)\n",
    "#df.to_csv(\"drive_minutes_matrix_fqhc.csv\",index = True)\n",
    "#data = pd.read_csv(\"drive_minutes_matrix_fqhc.csv\", index_col=0, header=0)\n",
    "#data = data.fillna(0)\n",
    "data.to_csv(\"drive_matrix_fqhc.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqhc_t_car = pd.read_csv(\"drive_matrix_fqhc.csv\",\n",
    "                        index_col=0,\n",
    "                        header=0)\n",
    "fqhc_t_pub = pd.read_csv(\"transit_matrix_fqhc.csv\",\n",
    "                        index_col=0,\n",
    "                        header=0)\n",
    "fqhc_t_walk = pd.read_csv(\"walking_matrix_fqhc.csv\",\n",
    "                        index_col=0,\n",
    "                        header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqhc_loc_dtilde = calc_dtilde_matrix(health_centers, t_car, t_pub, t_walk)\n",
    "fqhc_loc_d_matrix = calc_d_matrix(fqhc_loc_dtilde, health_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1           2    3           4           5    6    7    8    9    ...  \\\n",
      "0  0.0  NaN         NaN  NaN         NaN         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "1  NaN  0.0         NaN  NaN         NaN         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "2  NaN  NaN    0.000000  NaN  903.671334         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "3  NaN  NaN         NaN  0.0         NaN         NaN  NaN  NaN  NaN  NaN  ...   \n",
      "4  NaN  NaN  903.671334  NaN    0.000000  245.742626  NaN  NaN  NaN  NaN  ...   \n",
      "\n",
      "   401         402        403  404  405  406  407  408  409         410  \n",
      "0  NaN         NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  696.437903  \n",
      "1  NaN         NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "2  NaN  232.914218        NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "3  NaN         NaN  88.047353  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "4  NaN  150.470140        NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN  \n",
      "\n",
      "[5 rows x 411 columns]\n",
      "   0    1           2    3           4           5    6    7    8    9    ...  \\\n",
      "0  0.0  0.0    0.000000  0.0    0.000000    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "1  0.0  0.0    0.000000  0.0    0.000000    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "2  0.0  0.0    0.000000  0.0  903.671334    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "3  0.0  0.0    0.000000  0.0    0.000000    0.000000  0.0  0.0  0.0  0.0  ...   \n",
      "4  0.0  0.0  903.671334  0.0    0.000000  245.742626  0.0  0.0  0.0  0.0  ...   \n",
      "\n",
      "   401         402        403  404  405  406  407  408  409         410  \n",
      "0  0.0    0.000000   0.000000  0.0  0.0  0.0  0.0  0.0  0.0  696.437903  \n",
      "1  0.0    0.000000   0.000000  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "2  0.0  232.914218   0.000000  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "3  0.0    0.000000  88.047353  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "4  0.0  150.470140   0.000000  0.0  0.0  0.0  0.0  0.0  0.0    0.000000  \n",
      "\n",
      "[5 rows x 411 columns]\n"
     ]
    }
   ],
   "source": [
    "np.save(\"fqhc_d_matrix.npy\", all_loc_d_matrix) \n",
    "data = np.load(\"fqhc_d_matrix.npy\")\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "df = df.fillna(0)\n",
    "print(df.head())\n",
    "df.to_csv('dtilde_matrix_fqhc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lac_sites = gpd.read_file('Los Angeles/fixed_files/lac_NoCatalina_polls.geojson')\n",
    "lac_neighbours = np.load(\"Los Angeles/lac_neighbors.npy\")\n",
    "for i,a in lac_sites.iterrows():\n",
    "    if a['address.zip'] == '90095':\n",
    "        lac_sites.at[i, 'address.zip'] = '90024'\n",
    "    elif a['address.zip'] == '90506':\n",
    "        lac_sites.at[i, 'address.zip'] = '90249'\n",
    "    elif a['address.zip'] == '91371':\n",
    "        lac_sites.at[i, 'address.zip'] = '91367'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lac_tcar = np.load(\"Los Angeles/fixed_files/lac_tcar_matrix_completed.npy\")\n",
    "lac_tpub = np.load(\"Los Angeles/fixed_files/lac_tpub_matrix_completed.npy\")\n",
    "# lac_twalk = calc_twalk_matrix(lac_sites, lac_neighbours)\n",
    "lac_twalk = np.load(\"walk_matrix_complete\\lac_walk.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lac_dtilde = calc_dtilde_matrix(lac_sites, lac_tcar, lac_tpub, lac_twalk, lac_neighbours)\n",
    "lac_d_matrix = calc_d_matrix(lac_dtilde, lac_sites, lac_neighbours)\n",
    "np.save(\"lac_d_matrix_updated.npy\", lac_d_matrix) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "manbronx_sites = gpd.read_file('NYC/manbronx_polls.geojson')\n",
    "manbronx_neighbours = np.load(\"NYC/manbronx_neighbors.npy\")\n",
    "for i,a in manbronx_sites.iterrows():\n",
    "    if a['address.zip'] == '10103':\n",
    "        manbronx_sites.at[i, 'address.zip'] = '10019'\n",
    "\n",
    "manbronx_tcar = np.load(\"NYC/manbronx_tcar_matrix_completed.npy\")\n",
    "manbronx_tpub = np.load(\"NYC/manbronx_tpub_matrix_completed.npy\")\n",
    "# manbronx_twalk = calc_twalk_matrix(manbronx_sites, manbronx_neighbours)\n",
    "manbronx_twalk = np.load(\"walk_matrix_complete\\manbronx_walk.npy\")\n",
    "\n",
    "manbronx_dtilde = calc_dtilde_matrix(manbronx_sites, manbronx_tcar, manbronx_tpub, manbronx_twalk, manbronx_neighbours)\n",
    "manbronx_d_matrix = calc_d_matrix(manbronx_dtilde, manbronx_sites, manbronx_neighbours)\n",
    "np.save(\"manbronx_d_matrix_updated.npy\", manbronx_d_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queensbrook_sites = gpd.read_file('NYC/queensbrook_polls.geojson')\n",
    "queensbrook_neighbours = np.load(\"NYC/queensbrook_neighbors.npy\")\n",
    "\n",
    "queensbrook_tcar = np.load(\"NYC/queensbrook_tcar_matrix_completed.npy\")\n",
    "queensbrook_tpub = np.load(\"NYC/queensbrook_tpub_matrix_completed.npy\")\n",
    "# queensbrook_twalk = calc_twalk_matrix(queensbrook_sites, queensbrook_neighbours)\n",
    "queensbrook_twalk = np.load(\"walk_matrix_complete\\queensbrook_walk.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      11249\n",
      "1      11233\n",
      "2      11001\n",
      "3      11001\n",
      "4      11001\n",
      "5      11001\n",
      "6      11004\n",
      "7      11005\n",
      "8      11040\n",
      "9      11040\n",
      "10     11040\n",
      "11     11040\n",
      "12     11040\n",
      "13     11101\n",
      "14     11101\n",
      "15     11104\n",
      "16     11106\n",
      "17     11101\n",
      "18     11101\n",
      "19     11101\n",
      "20     11105\n",
      "21     11102\n",
      "22     11102\n",
      "23     11102\n",
      "24     11105\n",
      "25     11103\n",
      "26     11377\n",
      "27     11104\n",
      "28     11104\n",
      "29     11377\n",
      "30     11105\n",
      "31     11106\n",
      "32     11106\n",
      "33     11101\n",
      "34     11101\n",
      "35     11109\n",
      "36     11201\n",
      "37     11201\n",
      "38     11201\n",
      "39     11201\n",
      "40     11201\n",
      "41     11201\n",
      "42     11203\n",
      "43     11203\n",
      "44     11203\n",
      "45     11203\n",
      "46     11203\n",
      "47     11203\n",
      "48     11204\n",
      "49     11204\n",
      "50     11214\n",
      "51     11204\n",
      "52     11204\n",
      "53     11204\n",
      "54     11205\n",
      "55     11205\n",
      "56     11205\n",
      "57     11205\n",
      "58     11205\n",
      "59     11206\n",
      "60     11206\n",
      "61     11206\n",
      "62     11206\n",
      "63     11206\n",
      "64     11206\n",
      "65     11206\n",
      "66     11208\n",
      "67     11207\n",
      "68     11207\n",
      "69     11207\n",
      "70     11207\n",
      "71     11212\n",
      "72     11208\n",
      "73     11208\n",
      "74     11208\n",
      "75     11208\n",
      "76     11207\n",
      "77     11208\n",
      "78     11208\n",
      "79     11208\n",
      "80     11208\n",
      "81     11209\n",
      "82     11209\n",
      "83     11209\n",
      "84     11228\n",
      "85     11209\n",
      "86     11209\n",
      "87     11209\n",
      "88     11210\n",
      "89     11203\n",
      "90     11211\n",
      "91     11222\n",
      "92     11222\n",
      "93     11211\n",
      "94     11211\n",
      "95     11211\n",
      "96     11212\n",
      "97     11212\n",
      "98     11212\n",
      "99     11212\n",
      "100    11212\n",
      "101    11212\n",
      "102    11212\n",
      "103    11212\n",
      "104    11213\n",
      "105    11213\n",
      "106    11213\n",
      "107    11213\n",
      "108    11213\n",
      "109    11225\n",
      "110    11214\n",
      "111    11214\n",
      "112    11214\n",
      "113    11214\n",
      "114    11214\n",
      "115    11215\n",
      "116    11215\n",
      "117    11215\n",
      "118    11215\n",
      "119    11215\n",
      "120    11217\n",
      "121    11215\n",
      "122    11217\n",
      "123    11216\n",
      "124    11216\n",
      "125    11216\n",
      "126    11216\n",
      "127    11216\n",
      "128    11213\n",
      "129    11216\n",
      "130    11217\n",
      "131    11217\n",
      "132    11201\n",
      "133    11217\n",
      "134    11217\n",
      "135    11219\n",
      "136    11218\n",
      "137    11218\n",
      "138    11218\n",
      "139    11219\n",
      "140    11219\n",
      "141    11219\n",
      "142    11219\n",
      "143    11204\n",
      "144    11219\n",
      "145    11220\n",
      "146    11220\n",
      "147    11220\n",
      "148    11220\n",
      "149    11220\n",
      "150    11221\n",
      "151    11221\n",
      "152    11237\n",
      "153    11221\n",
      "154    11216\n",
      "155    11221\n",
      "156    11233\n",
      "157    11222\n",
      "158    11222\n",
      "159    11222\n",
      "160    11222\n",
      "161    11204\n",
      "162    11223\n",
      "163    11223\n",
      "164    11223\n",
      "165    11223\n",
      "166    11223\n",
      "167    11223\n",
      "168    11224\n",
      "169    11224\n",
      "170    11224\n",
      "171    11225\n",
      "172    11225\n",
      "173    11225\n",
      "174    11225\n",
      "175    11225\n",
      "176    11226\n",
      "177    11226\n",
      "178    11226\n",
      "179    11226\n",
      "180    11226\n",
      "181    11226\n",
      "182    11203\n",
      "183    11230\n",
      "184    11228\n",
      "185    11219\n",
      "186    11228\n",
      "187    11228\n",
      "188    11228\n",
      "189    11229\n",
      "190    11229\n",
      "191    11229\n",
      "192    11229\n",
      "193    11234\n",
      "194    11223\n",
      "195    11204\n",
      "196    11230\n",
      "197    11210\n",
      "198    11230\n",
      "199    11230\n",
      "200    11231\n",
      "201    11231\n",
      "202    11231\n",
      "203    11231\n",
      "204    11232\n",
      "205    11232\n",
      "206    11232\n",
      "207    11233\n",
      "208    11212\n",
      "209    11233\n",
      "210    11213\n",
      "211    11233\n",
      "212    11234\n",
      "213    11234\n",
      "214    11234\n",
      "215    11234\n",
      "216    11234\n",
      "217    11234\n",
      "218    11235\n",
      "219    11235\n",
      "220    11235\n",
      "221    11235\n",
      "222    11236\n",
      "223    11236\n",
      "224    11236\n",
      "225    11236\n",
      "226    11236\n",
      "227    11236\n",
      "228    11236\n",
      "229    11221\n",
      "230    11206\n",
      "231    11221\n",
      "232    11206\n",
      "233    11238\n",
      "234    11205\n",
      "235    11238\n",
      "236    11238\n",
      "237    11238\n",
      "238    11238\n",
      "239    11239\n",
      "240    11239\n",
      "241    11249\n",
      "242    11211\n",
      "243    11249\n",
      "244    11249\n",
      "245    11356\n",
      "246    11355\n",
      "247    11354\n",
      "248    11354\n",
      "249    11354\n",
      "250    11357\n",
      "251    11355\n",
      "252    11365\n",
      "253    11355\n",
      "254    11356\n",
      "255    11357\n",
      "256    11357\n",
      "257    11358\n",
      "258    11358\n",
      "259    11365\n",
      "260    11358\n",
      "261    11360\n",
      "262    11357\n",
      "263    11361\n",
      "264    11361\n",
      "265    11364\n",
      "266    11427\n",
      "267    11362\n",
      "268    11362\n",
      "269    11363\n",
      "270    11363\n",
      "271    11364\n",
      "272    11364\n",
      "273    11364\n",
      "274    11364\n",
      "275    11367\n",
      "276    11365\n",
      "277    11365\n",
      "278    11366\n",
      "279    11367\n",
      "280    11367\n",
      "281    11367\n",
      "282    11366\n",
      "283    11368\n",
      "284    11368\n",
      "285    11368\n",
      "286    11368\n",
      "287    11368\n",
      "288    11369\n",
      "289    11369\n",
      "290    11369\n",
      "291    11370\n",
      "292    11370\n",
      "293    11372\n",
      "294    11372\n",
      "295    11372\n",
      "296    11372\n",
      "297    11373\n",
      "298    11373\n",
      "299    11373\n",
      "300    11373\n",
      "301    11373\n",
      "302    11373\n",
      "303    11373\n",
      "304    11374\n",
      "305    11374\n",
      "306    11375\n",
      "307    11375\n",
      "308    11374\n",
      "309    11375\n",
      "310    11375\n",
      "311    11377\n",
      "312    11377\n",
      "313    11377\n",
      "314    11377\n",
      "315    11377\n",
      "316    11378\n",
      "317    11378\n",
      "318    11378\n",
      "319    11378\n",
      "320    11379\n",
      "321    11379\n",
      "322    11379\n",
      "323    11385\n",
      "324    11385\n",
      "325    11385\n",
      "326    11385\n",
      "327    11385\n",
      "328    11385\n",
      "329    11411\n",
      "330    11411\n",
      "331    11411\n",
      "332    11412\n",
      "333    11412\n",
      "334    11412\n",
      "335    11413\n",
      "336    11413\n",
      "337    11422\n",
      "338    11413\n",
      "339    11413\n",
      "340    11414\n",
      "341    11414\n",
      "342    11414\n",
      "343    11415\n",
      "344    11415\n",
      "345    11418\n",
      "346    11416\n",
      "347    11416\n",
      "348    11421\n",
      "349    11417\n",
      "350    11420\n",
      "351    11417\n",
      "352    11417\n",
      "353    11418\n",
      "354    11418\n",
      "355    11418\n",
      "356    11419\n",
      "357    11420\n",
      "358    11420\n",
      "359    11420\n",
      "360    11420\n",
      "361    11421\n",
      "362    11421\n",
      "363    11421\n",
      "364    11422\n",
      "365    11422\n",
      "366    11412\n",
      "367    11423\n",
      "368    11423\n",
      "369    11427\n",
      "370    11426\n",
      "371    11426\n",
      "372    11427\n",
      "373    11428\n",
      "374    11427\n",
      "375    11428\n",
      "376    11428\n",
      "377    11429\n",
      "378    11429\n",
      "379    11432\n",
      "380    11432\n",
      "381    11432\n",
      "382    11432\n",
      "383    11433\n",
      "384    11433\n",
      "385    11434\n",
      "386    11434\n",
      "387    11434\n",
      "388    11434\n",
      "389    11435\n",
      "390    11436\n",
      "391    11435\n",
      "392    11435\n",
      "393    11432\n",
      "394    11435\n",
      "395    11434\n",
      "396    11366\n",
      "397    11691\n",
      "398    11691\n",
      "399    11691\n",
      "400    11691\n",
      "401    11691\n",
      "402    11692\n",
      "403    11692\n",
      "404    11692\n",
      "405    11692\n",
      "406    11693\n",
      "407    11693\n",
      "408    11693\n",
      "409    11694\n",
      "410    11694\n",
      "411    11694\n",
      "412    11697\n",
      "Name: address.zip, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(queensbrook_sites['address.zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "queensbrook_dtilde = calc_dtilde_matrix(queensbrook_sites, queensbrook_tcar, queensbrook_tpub, queensbrook_twalk, queensbrook_neighbours)\n",
    "queensbrook_d_matrix = calc_d_matrix(queensbrook_dtilde, queensbrook_sites, queensbrook_neighbours)\n",
    "np.save(\"queensbrook_d_matrix_updated.npy\", queensbrook_d_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_sites = gpd.read_file('NYC/stat_polls.geojson')\n",
    "stat_neighbours = np.load(\"NYC/stat_neighbors.npy\")\n",
    "\n",
    "stat_tcar = np.load(\"NYC/stat_tcar_matrix_completed.npy\")\n",
    "stat_tpub = np.load(\"NYC/stat_tpub_matrix_completed.npy\")\n",
    "# stat_twalk = calc_twalk_matrix(stat_sites, stat_neighbours)\n",
    "stat_twalk = np.load(\"walk_matrix_complete\\stat_walk.npy\")\n",
    "\n",
    "stat_dtilde = calc_dtilde_matrix(stat_sites, stat_tcar, stat_tpub, stat_twalk, stat_neighbours)\n",
    "stat_d_matrix = calc_d_matrix(stat_dtilde, stat_sites, stat_neighbours)\n",
    "np.save(\"stat_d_matrix_updated.npy\", stat_d_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(over_18_pop_by_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"slc_twalk_matrix_completed.npy\", slc_twalk)\n",
    "np.save(\"atl_twalk_matrix_completed.npy\", atl_twalk)\n",
    "np.save(\"lac_twalk_matrix_completed.npy\", lac_twalk)\n",
    "np.save(\"chc_twalk_matrix_completed.npy\", chc_twalk)\n",
    "np.save(\"jax_twalk_matrix_completed.npy\", jax_twalk)\n",
    "np.save(\"queensbrook_twalk_matrix_completed.npy\", queensbrook_twalk)\n",
    "np.save(\"stat_twalk_matrix_completed.npy\", stat_twalk)\n",
    "np.save(\"manbronx_twalk_matrix_completed.npy\", manbronx_twalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "d_matrix_building.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
